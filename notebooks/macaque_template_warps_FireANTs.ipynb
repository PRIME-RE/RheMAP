{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration across Macaque MRI templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Chris Klink (c.klink@nin.knaw.nl) & Nikoloz Sirmpilatze (niko.sirbiladze@gmail.com)               \n",
    "**Last updated:** June 17, 2025     \n",
    "\n",
    "**Requirements:**    \n",
    "* _python_ >= 3.7\n",
    "* _nipype_ >= 1.2.0\n",
    "* _nilearn_ >= 0.5.2\n",
    "    * Used only for visualisation\n",
    "* _nibabel_ >= 2.3.3\n",
    "* _joblib_ >= 0.14.1\n",
    "    * Used only for parallel processing, not necessary when registrations are done serially\n",
    "* _ANTs_ >= 2.4.0\n",
    "    * _antsRegistration_,  _antsApplyTransforms_ and _antsAverageImages_ need to be in your path as executables    \\\n",
    "* _Numpy_\n",
    "\n",
    "When using the faster GPU-based FireAnts:\n",
    "* _fireANTS_     \n",
    "    * [https://github.com/rohitrango/fireants](https://github.com/rohitrango/fireants)     \n",
    "* _matplotlib_.pyplot    \n",
    "* _SimpleITK_    \n",
    "* _Pytorch_     \n",
    "\n",
    "**Citation**: Sirmpilatze, Nikoloz and Klink, P. Christiaan (2020). RheMAP: Non-linear warps between common rhesus macaque brain templates (Version 1.2)[Data set]. Zenodo. https://doi.org/10.5281/zenodo.3786357     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following templates are used: \n",
    "1. [NMT v1.2](https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/nonhuman/macaque_tempatl/template_nmtv1.html)\n",
    "2. [NMT v1.3](https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/nonhuman/macaque_tempatl/template_nmtv1.html)\n",
    "3. [NMT v2.0](https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/nonhuman/macaque_tempatl/template_nmtv2.html)\n",
    "4. [D99](https://afni.nimh.nih.gov/Macaque)\n",
    "5. [INIA19](https://www.nitrc.org/projects/inia19/https://www.nitrc.org/projects/inia19/)\n",
    "6. [MNI macaque](http://www.bic.mni.mcgill.ca/ServicesAtlases/Macaque)\n",
    "7. [Yerkes19](https://github.com/Washington-University/NHPPipelines)\n",
    "8. [ONPRC18](https://www.nitrc.org/projects/onprc18_atlas)     \n",
    "9. [F99](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/XTRACT)\n",
    "10. [MEBRAINS](https://doi.org/10.25493/5454-ZEA)       \n",
    "\n",
    "Within this notebook, they are abbreviated as *NMTv12*, *NMTv13*, *NMTv20_sym*, *NMTv20_asym*, *NMTv20_05mm_sym_brain*, and *NMTv20_05mm_asym*, *D99*, *INIA*, *MNI*, *YRK*, *ONPRC18*, *F99*, and *MEBRAINS*.     \n",
    "\n",
    "**NB!** We do not provide copies of the actual templates (licenses often forbids redistribution), but instead suggest you follow the links above and get them at the source. We do offer the warp files and warped templates that will be produced by this workflow. They can be downloaded from [Zenodo](https://doi.org/10.5281/zenodo.3786357) or [G-NODE GIN](https://gin.g-node.org/ChrisKlink/RheMAP). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to emulate this code, you can consider setting up your templates in the following folder structure:    \n",
    "\n",
    "|--- RheMAP   \n",
    "&emsp; |--- notebooks     \n",
    "&emsp; |--- templates     \n",
    "&emsp; &emsp; |--- D99     \n",
    "&emsp; &emsp; &emsp; |--- D99_atlas_1.2a.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_atlas_1.2a_in_MNI.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_template.nii.gz      \n",
    "&emsp; &emsp; |--- F99     \n",
    "&emsp; &emsp; &emsp; |--- struct.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- struct_brain.nii.gz \n",
    "&emsp; &emsp; |--- INIA   \n",
    "&emsp; &emsp; &emsp; |--- inia19-t1-brain_truncated.nii.gz      \n",
    "&emsp; &emsp; |--- MNI     \n",
    "&emsp; &emsp; &emsp; |--- macaque_25_model-MNI_brain.nii.gz      \n",
    "&emsp; &emsp; |--- MEBRAINS     \n",
    "&emsp; &emsp; &emsp; |--- MEBRAINS_T1_masked.nii.gz      \n",
    "&emsp; &emsp; |--- NMT     \n",
    "&emsp; &emsp; &emsp; |--- NMT_v1.2     \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_SS.nii.gz      \n",
    "&emsp; &emsp; &emsp; |--- NMT_v1.3     \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_SS.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- NMT_v2.0     \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_v2.0_asym_05mm_SS.nii.gz  \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_v2.0_asym_SS.nii.gz  \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_v2.0_sym_05mm_SS.nii.gz  \n",
    "&emsp; &emsp; &emsp; &emsp; |--- NMT_v2.0_sym_SS.nii.gz  \n",
    "&emsp; &emsp; |--- ONPRC18     \n",
    "&emsp; &emsp; &emsp; |--- ONPRC18_T1W.nii.gz  \n",
    "&emsp; &emsp; |--- YRK      \n",
    "&emsp; &emsp; &emsp; |--- MacaqueYerkes19_T1w_0.5mm_brain.nii.gz       \n",
    "\n",
    "After downloading the warp files and warped templates from [Zenodo](https://zenodo.org/record/3776856#.XqqfI3UzZjE), we suggest you include them like this:      \n",
    "\n",
    "|--- RheMAP   \n",
    "&emsp; |--- notebooks     \n",
    "&emsp; |--- templates     \n",
    "&emsp; |--- warps       \n",
    "&emsp; &emsp; |--- final     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_INIA_CompositeWarp.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_MNI_CompositeWarp.nii.gz      \n",
    "&emsp; &emsp; &emsp; |--- etc   \n",
    "&emsp; &emsp; |--- linear     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_INIA_affine_0GenericAffine.mat     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_MNI_affine_0GenericAffine.mat     \n",
    "&emsp; &emsp; &emsp; |--- etc   \n",
    "&emsp; &emsp; |--- nonlinear     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_INIA_1InverseWarp.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_INIA_1Warp.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_MNI_1InverseWarp.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_to_MNI_1Warp.nii.gz  \n",
    "&emsp; &emsp; &emsp; |--- etc   \n",
    "&emsp; |--- warped_templates       \n",
    "&emsp; &emsp; |--- final     \n",
    "&emsp; &emsp; &emsp; |--- D99_in_INIA_composite.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_in_MNI_composite.nii.gz       \n",
    "&emsp; &emsp; &emsp; |--- etc   \n",
    "&emsp; &emsp; |--- linear     \n",
    "&emsp; &emsp; &emsp; |--- D99_in_INIA_linear.nii.gz    \n",
    "&emsp; &emsp; &emsp; |--- D99_in_MNI_linear.nii.gz          \n",
    "&emsp; &emsp; &emsp; |--- etc   \n",
    "&emsp; &emsp; |--- nonlinear     \n",
    "&emsp; &emsp; &emsp; |--- D99_in_INIA_linear+SyN.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- D99_in_MNI_linear+SyN.nii.gz     \n",
    "&emsp; &emsp; &emsp; |--- etc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the warp files and warped templates you could of course reconstruct the original templates with something like the following.     \n",
    "\n",
    "On the command line:     \n",
    "```bash\n",
    "antsApplyTransforms -i <TEMPLATE1_in_TEMPLATE2_composite.nii.gz> \\\n",
    "                    -r <TEMPLATE2_in_TEMPLATE1.nii.gz> \\        \n",
    "                    -o <RECONSTRUCTED_ORIGINAL_TEMPLATE1.nii.gz> \\\n",
    "                    -t [<TEMPLATE1_to_TEMPLATE2_CompositeWarp>,1] \\\n",
    "                    -n Linear \\\n",
    "                    -d 3\n",
    "```    \n",
    "\n",
    "In NiPype:     \n",
    "```python\n",
    "import nipype.interfaces.ants as ants    \n",
    "ants.ApplyTransforms(\n",
    "            input_image=<TEMPLATE1_in_TEMPLATE2_composite.nii.gz>,\n",
    "            reference_image=<TEMPLATE2_in_TEMPLATE1.nii.gz>,        \n",
    "            output_image=<RECONSTRUCTED_ORIGINAL_TEMPLATE1.nii.gz>,\n",
    "            transforms=<TEMPLATE1_to_TEMPLATE2_CompositeWarp>,\n",
    "            invert_transform_flags=True,\n",
    "            interpolation='Linear',\n",
    "            dimension=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end goal is to generate warps between each unique pair of the templates (forward and backward).\n",
    "* forwards (A to B, e.g. *NMTv1.2_to_D99*)\n",
    "* backwards (B to A, e.g. *D99_to_NMTv1.2*)\n",
    "\n",
    "![warps](RegisterTemplates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0a. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil as sh\n",
    "import nibabel as nb\n",
    "\n",
    "from itertools import combinations\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import nipype.interfaces.fsl as fsl # nipype interface for FSL\n",
    "import nipype.interfaces.ants as ants # nipype interface for ANTs\n",
    "from nilearn import plotting # Plotting function from nilearn\n",
    "\n",
    "from fireants.io import Image, BatchedImages\n",
    "from fireants.registration import AffineRegistration, GreedyRegistration\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import torch, os\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0b. Define relative paths to template files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skull-stripped isotropic volumetric images are used for registration.\n",
    "* For **NMT**, **D99**, and **YRK** the provided skull-stripped brains were used\n",
    "* In **INIA** the brain stem extends further down the spinal cord compared to the other temlplates, so the braisn stem was truncated at a level similar to the others\n",
    "* No skull-stripped image was provided with **MNI**, so the brain was segmented semi-manually using ITK-SNAP\n",
    "* For **YRK** we used the version provided together with [NHPPipelines](https://github.com/Washington-University/NHPPipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# NB! THIS COULD BE DIFFERENT FOR EVERY USER\n",
    "# ============================================\n",
    "BASE_path     = os.path.dirname(os.getcwd()) + '/'   # repo base folder\n",
    "print(BASE_path)\n",
    "\n",
    "# these follow the directory structure as outline above\n",
    "TEMPLATE_path = BASE_path + 'templates/'                   # templates base folder\n",
    "NMTv12_path   = TEMPLATE_path + 'NMT/NMT_v1.2/'\n",
    "NMTv13_path   = TEMPLATE_path + 'NMT/NMT_v1.3/'\n",
    "NMTv20_path   = TEMPLATE_path + 'NMT/NMT_v2.0/'\n",
    "D99_path      = TEMPLATE_path + 'D99/'\n",
    "F99_path      = TEMPLATE_path + 'F99/'\n",
    "INIA_path     = TEMPLATE_path + 'INIA/'\n",
    "MNI_path      = TEMPLATE_path + 'MNI/'\n",
    "YRK_path      = TEMPLATE_path + 'YRK/'\n",
    "ONPRC18_path  = TEMPLATE_path + 'ONPRC18/'\n",
    "MEBRAINS_path  = TEMPLATE_path + 'MEBRAINS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMTv12_brain = NMTv12_path + 'NMT_SS.nii.gz'\n",
    "NMTv13_brain = NMTv13_path + 'NMT_SS.nii.gz'\n",
    "NMTv20_sym_brain = NMTv20_path + 'NMT_v2.0_sym_SS.nii.gz'\n",
    "NMTv20_05mm_sym_brain = NMTv20_path + 'NMT_v2.0_sym_05mm_SS.nii.gz'\n",
    "NMTv20_asym_brain = NMTv20_path + 'NMT_v2.0_asym_SS.nii.gz'\n",
    "NMTv20_05mm_asym_brain = NMTv20_path + 'NMT_v2.0_asym_05mm_SS.nii.gz'\n",
    "D99_brain    = D99_path + 'D99_template.nii.gz'\n",
    "F99_brain    = F99_path + 'struct_brain.nii.gz'\n",
    "INIA_brain   = INIA_path + 'inia19-t1-brain_truncated.nii.gz'\n",
    "MNI_brain    = MNI_path + 'macaque_25_model-MNI_brain.nii.gz'\n",
    "YRK_brain    = YRK_path + 'MacaqueYerkes19_T1w_0.5mm_brain.nii.gz'\n",
    "ONPRC18_brain = ONPRC18_path + 'ONPRC18_T1W.nii.gz'\n",
    "MEBRAINS_brain = MEBRAINS_path + 'MEBRAINS_T1_masked.nii.gz'\n",
    "\n",
    "temp_names   = ['NMTv1.2', 'NMTv1.3',\n",
    "                'NMTv2.0-sym','NMTv2.0-0.5mm-sym',\n",
    "                'NMTv2.0-asym','NMTv2.0-0.5mm-asym',\n",
    "                'D99', 'F99', 'INIA', 'MNI',\n",
    "                'YRK', 'ONPRC18','MEBRAINS']\n",
    "temp_brains  = [NMTv12_brain, NMTv13_brain, \n",
    "                NMTv20_sym_brain, NMTv20_05mm_sym_brain,\n",
    "                NMTv20_asym_brain,NMTv20_05mm_asym_brain,\n",
    "                D99_brain, F99_brain, INIA_brain, MNI_brain,\n",
    "                YRK_brain, ONPRC18_brain, MEBRAINS_brain]\n",
    "\n",
    "temp_names   = ['ONPRC18','MEBRAINS']\n",
    "temp_brains  = [ONPRC18_brain, MEBRAINS_brain]\n",
    "\n",
    "\n",
    "# strength of contrast in the plot_anat function (\"dim\")\n",
    "contrasts = [0]*len(temp_brains) # create a list of zeros because this should exist\n",
    "#contrasts = [-1, 0, 0, 0, 0, 0, 0, -1, -1, -0.5, 0, 0, 0] # specify to improve display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step you can create a subset of the templates to include in creating the warps. This can be useful when you add a new template and want to warp it to templates that have pre-existing warps (to each other). This way you can generate the new unique temlates without redoing the prexisting ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_pairs_with = temp_names # all included\n",
    "include_pairs_with = ['MEBRAINS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headers of NMT > v1.3 has both qform_code and sform_code set to 5. This is a relatively new definition ([see NITRC](https://www.nitrc.org/forum/forum.php?thread_id=10029&forum_id=1942)). Older version of nibabel (< 2.4.0) only recognized values 0-4 and reset the 5 to 0 which causes weird plotting artefacts (registrations will still be ok). As a workaround, you can use the code below to change the header value from 5 to something like 2 ('aligned'). A better option would of course be to update nibabel.\n",
    "```\n",
    "if NMTv13_brain in locals():\n",
    "    sh.copyfile(NMTv13_brain,NMTv13_brain + '.bak'); # back up the original file\n",
    "    img = nb.load(NMTv13_brain)\n",
    "    hdr = img.header\n",
    "    hdr.set_qform(hdr.get_qform(),code=2)\n",
    "    hdr.set_sform(hdr.get_sform(),code=2)\n",
    "    nb.save(img, NMTv13_brain) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0c. Plot template brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, brain,con in zip(temp_names, temp_brains, contrasts):\n",
    "    if name in include_pairs_with:\n",
    "        display = plotting.plot_anat(brain, display_mode='ortho', title=name, \n",
    "                  draw_cross=False, annotate=True, dim=con);\n",
    "        plt.savefig(name + '_template.png'); # save png\n",
    "        plt.draw()\n",
    "        #display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Perform registration\n",
    "* This is performed using [FireANTs](https://github.com/rohitrango/fireants) **Affine** registration (12 degrees of freedom: 3 translations + 3 rotations + 3 scalings + 3 shears)\n",
    "* It employs PyTorch and does the registration on the GPU (fast) but because of memory management we will have to do pairs of templates in a serial fashion rather than separate the the affine and non-linear steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize an image to 0-100\n",
    "def normalize_and_wrap_image(path, new_min=0.0, new_max=100.0):\n",
    "    \"\"\"\n",
    "    Load image via sitk, normalize intensity, save to temp file, and return FireANTs Image.\n",
    "    \"\"\"\n",
    "    img = sitk.ReadImage(path)\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "\n",
    "    arr_min = arr.min()\n",
    "    arr_max = arr.max()\n",
    "\n",
    "    if arr_max > arr_min:\n",
    "        arr = (arr - arr_min) / (arr_max - arr_min)\n",
    "        arr = arr * (new_max - new_min) + new_min\n",
    "    else:\n",
    "        arr[:] = new_min  # if flat\n",
    "\n",
    "    norm_img = sitk.GetImageFromArray(arr)\n",
    "    norm_img.CopyInformation(img)\n",
    "\n",
    "    # Save to temp file\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix='.nii.gz', delete=False)\n",
    "    sitk.WriteImage(norm_img, temp_file.name)\n",
    "    temp_file.close()\n",
    "\n",
    "    return Image.load_file(temp_file.name), temp_file.name\n",
    "\n",
    "# check if initial alignment is needed\n",
    "# you may need to tinker with this threshold a bit\n",
    "def needs_init(imgfix, imgmov, threshold_mm=20):\n",
    "    fixed = sitk.ReadImage(imgfix)\n",
    "    moving = sitk.ReadImage(imgmov)\n",
    "\n",
    "    # Compute physical center of each image\n",
    "    def get_center(img):\n",
    "        size = np.array(img.GetSize())\n",
    "        spacing = np.array(img.GetSpacing())\n",
    "        origin = np.array(img.GetOrigin())\n",
    "        direction = np.array(img.GetDirection()).reshape(3, 3)\n",
    "        center_index = size / 2.0\n",
    "        center_phys = origin + direction.dot(center_index * spacing)\n",
    "        return center_phys\n",
    "\n",
    "    center_fixed = get_center(fixed)\n",
    "    center_moving = get_center(moving)\n",
    "\n",
    "    dist = np.linalg.norm(center_fixed - center_moving)\n",
    "    print(f\"Distance between centers: {dist} mm\")\n",
    "    return dist > threshold_mm\n",
    "\n",
    "# compute initial alignment by center of mass\n",
    "def get_com_init(imgfix,imgmov):\n",
    "    fixed = sitk.ReadImage(imgfix, sitk.sitkFloat32)\n",
    "    moving = sitk.ReadImage(imgmov, sitk.sitkFloat32)\n",
    "\n",
    "    # Get an affine transform that aligns the geometric centers\n",
    "    transform = sitk.CenteredTransformInitializer(\n",
    "        fixed, moving,\n",
    "        sitk.AffineTransform(3),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "    )\n",
    "\n",
    "    # Extract matrix and translation\n",
    "    matrix = np.array(transform.GetMatrix()).reshape(3, 3)\n",
    "    translation = np.array(transform.GetTranslation())\n",
    "\n",
    "    # Construct full 4x4 affine matrix\n",
    "    affine_np = np.eye(4, dtype=np.float32)\n",
    "    affine_np[:3, :3] = matrix\n",
    "    affine_np[:3, 3] = translation\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    init_affine = torch.tensor(affine_np, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    return init_affine\n",
    "\n",
    "# save image from tensor to file\n",
    "def save_image(tensor_img, reference_path, out_path):\n",
    "    ref_img = sitk.ReadImage(reference_path)\n",
    "    arr = tensor_img[0, 0].detach().cpu().numpy()\n",
    "    img = sitk.GetImageFromArray(arr)\n",
    "    img.SetOrigin(ref_img.GetOrigin())\n",
    "    img.SetSpacing(ref_img.GetSpacing())\n",
    "    img.SetDirection(ref_img.GetDirection())\n",
    "    sitk.WriteImage(img, out_path)\n",
    "\n",
    "# run affine registration\n",
    "def run_affine_registration(mov_brain, targ_brain, outbase, init_affine=None):\n",
    "    imagefix, fix_temp_path = normalize_and_wrap_image(targ_brain)\n",
    "    imagemov, mov_temp_path = normalize_and_wrap_image(mov_brain)\n",
    "    normalized_paths = [fix_temp_path, mov_temp_path]\n",
    "    batchfix, batchmov = BatchedImages([imagefix]), BatchedImages([imagemov])\n",
    "\n",
    "    if init_affine is None:\n",
    "        if needs_init(targ_brain, mov_brain):\n",
    "            print(\"Initial alignment needed, computing center of mass...\")\n",
    "            init_affine = get_com_init(targ_brain, mov_brain)\n",
    "\n",
    "    affine = AffineRegistration(\n",
    "        scales=[4, 2, 1], iterations=[200, 100, 50],\n",
    "        fixed_images=batchfix, moving_images=batchmov,\n",
    "        optimizer='Adam', optimizer_lr=3e-3, cc_kernel_size=5,\n",
    "        init_rigid=init_affine\n",
    "    )\n",
    "    transformed = affine.optimize(save_transformed=True)\n",
    "    affine_txt = f\"{outbase[1]}_affine_0GenericAffine.txt\"\n",
    "    affine_mat = f\"{outbase[1]}_affine_0GenericAffine.mat\"\n",
    "    affine.save_as_ants_transforms(affine_txt)\n",
    "    os.system(f\"ConvertTransformFile 3 {affine_txt} {affine_mat} --homogeneousMatrix\")\n",
    "\n",
    "    save_image(transformed[-1], targ_brain, f\"{outbase[0]}_linear.nii.gz\")\n",
    "    return affine, batchfix, batchmov\n",
    "\n",
    "# run nonlinear registration using GreedyRegistration\n",
    "def run_nonlinear_registration(fix, mov, outbase, ref_path, init_affine=None, suffix='composite'):\n",
    "    reg = GreedyRegistration(\n",
    "        scales=[4, 2, 1], iterations=[200, 100, 25],\n",
    "        fixed_images=fix, moving_images=mov,\n",
    "        cc_kernel_size=5, deformation_type='compositive',\n",
    "        smooth_grad_sigma=1,\n",
    "        optimizer='adam', optimizer_lr=0.5,\n",
    "        init_affine=init_affine\n",
    "    )\n",
    "    reg.optimize(save_transformed=False)\n",
    "    torch.save(reg.get_warped_coordinates(fix, mov), f\"{outbase[1]}_warp.pt\")\n",
    "    if suffix == 'composite':\n",
    "        reg.save_as_ants_transforms(f\"{outbase[1]}_CompositeWarp.nii.gz\")\n",
    "    elif suffix == 'linear+SyN':\n",
    "        reg.save_as_ants_transforms(f\"{outbase[1]}_1Warp.nii.gz\")\n",
    "    save_image(reg.evaluate(fix, mov), ref_path, f\"{outbase[0]}_{suffix}.nii.gz\")\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names, brains in zip(combinations(temp_names, 2), combinations(temp_brains, 2)):\n",
    "    mov_pref, targ_pref = names\n",
    "    mov_brain, targ_brain = brains\n",
    "\n",
    "    if mov_pref not in include_pairs_with and targ_pref not in include_pairs_with:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nRegistering {mov_pref} to {targ_pref}...\")\n",
    "    outbase = [f\"{mov_pref}_in_{targ_pref}\", f\"{mov_pref}_to_{targ_pref}\"]\n",
    "\n",
    "    affine, batchfix, batchmov = run_affine_registration(mov_brain, targ_brain, outbase)\n",
    "    reg = run_nonlinear_registration(batchfix, batchmov, outbase, targ_brain, init_affine=affine.get_affine_matrix().detach())\n",
    "\n",
    "    print(f\"\\nNon-linear only (SyN) {mov_pref} to {targ_pref}...\")\n",
    "    imagemov, mov_temp_path = normalize_and_wrap_image(f\"{outbase[0]}_linear.nii.gz\")\n",
    "    normalized_paths = [mov_temp_path]\n",
    "    syn_batchmov = BatchedImages([imagemov])\n",
    "    run_nonlinear_registration(batchfix, syn_batchmov, outbase, targ_brain, suffix='linear+SyN')\n",
    "\n",
    "    print(f\"\\nRegistering inverse {targ_pref} to {mov_pref}...\")\n",
    "    inv_outbase = [f\"{targ_pref}_in_{mov_pref}\", f\"{targ_pref}_to_{mov_pref}\"]\n",
    "    affine_inv, batchfix_inv, batchmov_inv = run_affine_registration(targ_brain, mov_brain, inv_outbase)\n",
    "    reg_inv = run_nonlinear_registration(batchfix_inv, batchmov_inv, inv_outbase, mov_brain, init_affine=affine_inv.get_affine_matrix().detach())\n",
    "\n",
    "    print(f\"\\nNon-linear only (SyN) inverse {targ_pref} to {mov_pref}...\")\n",
    "    imagemov_inv, movinv_temp_path = normalize_and_wrap_image(f\"{inv_outbase[0]}_linear.nii.gz\")\n",
    "    normalized_paths = [movinv_temp_path]\n",
    "    syn_batchmov_inv = BatchedImages([imagemov_inv])\n",
    "    run_nonlinear_registration(batchfix_inv, syn_batchmov_inv, inv_outbase, mov_brain, suffix='linear+SyN')\n",
    "\n",
    "    del affine, reg, affine_inv, reg_inv\n",
    "    del batchfix, batchmov, batchfix_inv, batchmov_inv\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Clean up temporary files\n",
    "for path in normalized_paths:\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to remove temp file {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualize results\n",
    "### 2a. Visualize linear registration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for names, brains in zip(combinations(temp_names, 2), combinations(temp_brains, 2)):\n",
    "    if names[0] in include_pairs_with or names[1] in include_pairs_with:\n",
    "        mov_pref = names[0]\n",
    "        targ_pref = names[1]\n",
    "        mov_brain = brains[0]\n",
    "        targ_brain = brains[1]\n",
    "        targ_index = temp_names.index(targ_pref)\n",
    "\n",
    "        display = plotting.plot_anat(targ_brain, display_mode='ortho',\n",
    "                            title='{0} edges on {1} volume'.format(mov_pref, targ_pref),\n",
    "                            draw_cross=False, annotate=False, dim=contrasts[targ_index])\n",
    "        brain = '{0}_in_{1}_linear.nii.gz'.format(mov_pref, targ_pref)\n",
    "        #display.add_edges(brain)\n",
    "        display.add_contours(brain)\n",
    "        plt.savefig('Linear_{0}_on_{1}.png'.format(mov_pref, targ_pref))\n",
    "        plt.draw()\n",
    "        display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b: Visualize non-linear registration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names, brains in zip(combinations(temp_names, 2), combinations(temp_brains, 2)):\n",
    "    if names[0] in include_pairs_with or names[1] in include_pairs_with:\n",
    "        mov_pref = names[0]\n",
    "        targ_pref = names[1]\n",
    "        targ_brain = brains[1]\n",
    "        targ_index = temp_names.index(targ_pref)\n",
    "\n",
    "        display = plotting.plot_anat(targ_brain, display_mode='ortho',\n",
    "                            title='{0} edges on {1} volume'.format(mov_pref, targ_pref),\n",
    "                            draw_cross=False, annotate=False, dim=contrasts[targ_index])\n",
    "        brain = '{0}_in_{1}_linear+SyN.nii.gz'.format(mov_pref, targ_pref)\n",
    "        #display.add_edges(brain)\n",
    "        display.add_contours(brain)\n",
    "        plt.savefig('Nonlinear_{0}_on_{1}.png'.format(mov_pref, targ_pref))\n",
    "        plt.draw()\n",
    "        display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c: Visualize composite registration results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for names, brains in zip(combinations(temp_names, 2), combinations(temp_brains, 2)):\n",
    "    if names[0] in include_pairs_with or names[1] in include_pairs_with:\n",
    "        mov_pref = names[0]\n",
    "        targ_pref = names[1]\n",
    "        mov_brain = brains[0]\n",
    "        targ_brain = brains[1]\n",
    "        mov_index = temp_names.index(mov_pref)\n",
    "        targ_index = temp_names.index(targ_pref)\n",
    "\n",
    "        display = plotting.plot_anat(targ_brain, display_mode='ortho',\n",
    "                            title='{0} edges on {1} volume'.format(mov_pref, targ_pref),\n",
    "                            draw_cross=False, annotate=False, dim=contrasts[targ_index])\n",
    "        brain = '{0}_in_{1}_composite.nii.gz'.format(mov_pref, targ_pref)\n",
    "        #display.add_edges(brain)\n",
    "        display.add_contours(brain)\n",
    "        plt.savefig('Composite_{0}_on_{1}.png'.format(mov_pref, targ_pref))\n",
    "        plt.draw()\n",
    "        display.close()\n",
    "\n",
    "        display = plotting.plot_anat(mov_brain, display_mode='ortho',\n",
    "                            title='{1} edges on {0} volume'.format(mov_pref, targ_pref),\n",
    "                            draw_cross=False, annotate=False, dim=contrasts[mov_index])\n",
    "        brain = '{1}_in_{0}_composite.nii.gz'.format(mov_pref, targ_pref)\n",
    "        #display.add_edges(brain)\n",
    "        display.add_contours(brain)\n",
    "        plt.savefig('Composite_{1}_on_{0}.png'.format(mov_pref, targ_pref))\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean-up\n",
    "* Create subfolders for linear and non-linear warps, and for the warped volumes\n",
    "* Put all files in sensible subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(BASE_path + \"warps/linear\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"warps/nonlinear\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"warps/final\" , exist_ok=True)\n",
    "\n",
    "# [os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/linear/\" + f) for f in glob.glob('*_affine_*Affine.mat')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/nonlinear/\" + f) for f in glob.glob('*_to_*_1Warp.nii.gz')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/nonlinear/\" + f) for f in glob.glob('*_to_*_1InverseWarp.nii.gz')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/final/\" + f) for f in glob.glob('*_to_*_CompositeWarp.nii.gz')];\n",
    "[os.remove(f) for f in glob.glob('*Affine.mat')]; # spurious linear warps (generated by nonlinear)\n",
    "\n",
    "os.makedirs(BASE_path + \"warped_templates/linear\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"warped_templates/nonlinear\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"warped_templates/final\" , exist_ok=True)\n",
    "\n",
    "[os.rename(os.getcwd() + '/' +  f, BASE_path + \"warped_templates/linear/\" + f) for f in glob.glob('*_in_*linear.nii.gz')];\n",
    "[os.rename(os.getcwd() + '/' +  f, BASE_path + \"warped_templates/nonlinear/\" + f) for f in glob.glob('*_in_*linear+SyN.nii.gz')];\n",
    "[os.rename(os.getcwd() + '/' +  f, BASE_path + \"warped_templates/final/\" + f) for f in glob.glob('*_in_*composite.nii.gz')];\n",
    "\n",
    "os.makedirs(BASE_path + \"images/templates\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"images/linear_reg\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"images/nonlinear_reg\" , exist_ok=True)\n",
    "os.makedirs(BASE_path + \"images/all_warp_pairs\" , exist_ok=True)\n",
    "\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"images/templates/\" + f) for f in glob.glob('*_template.png')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"images/linear_reg/\" + f) for f in glob.glob('Linear*.png')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"images/nonlinear_reg/\" + f) for f in glob.glob('Nonlinear*.png')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"images/all_warp_pairs/\" + f) for f in glob.glob('Composite*.png')];\n",
    "\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/linear/\" + f) for f in glob.glob('*_affine_*Affine.txt')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/nonlinear/\" + f) for f in glob.glob('*_to_*_warp.pt')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/nonlinear/\" + f) for f in glob.glob('*_to_*_warpinv.pt')];\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"warps/final/\" + f) for f in glob.glob('*_to_*_CompositeWarp.nii.gz')];    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. We will now create the average 'meta'-template in NMTv2.0 symmetric space (just because we can)\n",
    "* Get all the templates (in NMTv2.0 sym space) & average them into a 'MetaTemplate'\n",
    "* Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtp = BASE_path + \"warped_templates/final/\"\n",
    "image_list = [NMTv20_sym_brain]\n",
    "for file in os.listdir(wtp):\n",
    "    if file.split('_')[2] == 'NMTv2.0-sym':\n",
    "        image_list.append(wtp + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg = ants.AverageImages(\n",
    "    dimension=3,\n",
    "    output_average_image=\"MetaTemplate_in_NMTv2.0-sym.nii.gz\",\n",
    "    normalize=True,\n",
    "    images=image_list\n",
    ");\n",
    "avg.run();\n",
    "\n",
    "plotting.plot_anat(\"MetaTemplate_in_NMTv2.0-sym.nii.gz\", display_mode='ortho', \n",
    "          title=\"MetaTemplate in NMTv2.0-sym\", draw_cross=False, annotate=True, dim=con);\n",
    "plt.savefig('MetaTemplate_in_NMTv2.0-sym.png')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(BASE_path + \"warped_templates/metatemplate\" , exist_ok=True)\n",
    "[os.rename(os.getcwd() + '/' +  f, BASE_path + \"warped_templates/metatemplate/\" + f) for f in glob.glob('MetaTemplate*.nii.gz')];\n",
    "os.makedirs(BASE_path + \"images/metatemplate\" , exist_ok=True)\n",
    "[os.rename(os.getcwd() + '/' + f, BASE_path + \"images/metatemplate/\" + f) for f in glob.glob('MetaTemplate*.png')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
